{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据用户特征和电影特征onehot/multihot编码后进行推荐\n",
    "\n",
    "# 尝试使用GBDT和DNN进行推荐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入scikit-learn用于one-hot编码\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# movies.dat处理\n",
    "    one-hot编码\n",
    "    最后展示movieId和对应编码后特征array(99,)特征矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies属性one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_table('/Users/yihaoli/Desktop/dataset/movielens-1m-dataset/movies.dat',header=None,sep='::')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 考虑年份可以作为一个特征, 所以将名称属性中的年份提取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[3] = movies_df[1].apply(lambda x : re.findall('(?<=\\()[0-9]{4}(?=\\))',x)[-1], 1)\n",
    "movies_df[1] = movies_df[1].apply(lambda x : re.findall('^.+(?=\\([0-9]{4}\\))',x)[-1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3878</td>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3879</td>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3881</td>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3882</td>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                             1                             2     3\n",
       "0        1                    Toy Story    Animation|Children's|Comedy  1995\n",
       "1        2                      Jumanji   Adventure|Children's|Fantasy  1995\n",
       "2        3             Grumpier Old Men                 Comedy|Romance  1995\n",
       "3        4            Waiting to Exhale                   Comedy|Drama  1995\n",
       "4        5  Father of the Bride Part II                         Comedy  1995\n",
       "...    ...                           ...                           ...   ...\n",
       "3878  3948             Meet the Parents                         Comedy  2000\n",
       "3879  3949          Requiem for a Dream                          Drama  2000\n",
       "3880  3950                    Tigerland                          Drama  2000\n",
       "3881  3951             Two Family House                          Drama  2000\n",
       "3882  3952               Contender, The                 Drama|Thriller  2000\n",
       "\n",
       "[3883 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年份编码\n",
    "# 需要按照顺序\n",
    "# 所以操作相对多一些\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(movies_df.sort_values(3)[3].unique())\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "year_encoded = {}\n",
    "years = movies_df.sort_values(3)[3].unique()\n",
    "for i,y in enumerate(years):\n",
    "    year_encoded[y] = onehot_encoded[i,:]\n",
    "movies_df[3] = movies_df[3].map(year_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 电影类目multi-hot编码\n",
    "# 一个电影可能存在多个分类\n",
    "\n",
    "# 得到电影多个标签的one-hot编码\n",
    "def get_encoded(x, cat_encoded):\n",
    "    temp_list = x.split('|')\n",
    "    temp = np.zeros((len(onehot_encoded[0,:]),),dtype = np.float64)\n",
    "    for t in temp_list:\n",
    "        temp = temp + cat_encoded[t]\n",
    "    return temp\n",
    "\n",
    "cat_list = []\n",
    "for m in list(movies_df[2]):\n",
    "    temp_list = m.split('|')\n",
    "    for t in temp_list:\n",
    "        if t not in cat_list:\n",
    "            cat_list.append(t)\n",
    "cat_list = list(set(cat_list))\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(cat_list)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "cat_encoded = {}\n",
    "for i,c in enumerate(cat_list):\n",
    "    cat_encoded[c] = onehot_encoded[i,:]\n",
    "\n",
    "movies_df[2] = movies_df[2].map(lambda x:get_encoded(x,cat_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接列2和列3编码得到最后特征矩阵\n",
    "movies_df[4] = movies_df.apply(lambda x: np.concatenate([x[2],x[3]]),axis = 1)\n",
    "movies_df = movies_df[[0,4]]\n",
    "movies_df = movies_df.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3948</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3949</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3951</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3952</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      4\n",
       "0                                                      \n",
       "1     [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "3     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "5     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "...                                                 ...\n",
       "3948  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3949  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "3950  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "3951  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "3952  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "\n",
       "[3883 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# users.dat处理\n",
    "    one-hot编码\n",
    "    最后展示userId和对应编码后特征array(,)特征矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### users属性one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_table('/Users/yihaoli/Desktop/dataset/movielens-1m-dataset/users.dat',header=None,sep='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6035</td>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6036</td>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6037</td>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6038</td>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6039</td>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1   2   3      4\n",
       "0        1  F   1  10  48067\n",
       "1        2  M  56  16  70072\n",
       "2        3  M  25  15  55117\n",
       "3        4  M  45   7  02460\n",
       "4        5  M  25  20  55455\n",
       "...    ... ..  ..  ..    ...\n",
       "6035  6036  F  25  15  32603\n",
       "6036  6037  F  45   1  76006\n",
       "6037  6038  F  56   1  14706\n",
       "6038  6039  F  45   0  01060\n",
       "6039  6040  M  25   6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性别onehot编码\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(users_df.sort_values(1)[1].unique())\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "gender_encoded = {}\n",
    "genders = users_df.sort_values(1)[1].unique()\n",
    "for i,y in enumerate(genders):\n",
    "    gender_encoded[y] = onehot_encoded[i,:]\n",
    "users_df[1] = users_df[1].map(gender_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年龄onehot编码\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(users_df.sort_values(2)[2].unique())\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "age_encoded = {}\n",
    "ages = users_df.sort_values(2)[2].unique()\n",
    "for i,y in enumerate(ages):\n",
    "    age_encoded[y] = onehot_encoded[i,:]\n",
    "users_df[2] = users_df[2].map(age_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 职业onehot编码\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(users_df.sort_values(3)[3].unique())\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "occ_encoded = {}\n",
    "occs = users_df.sort_values(3)[3].unique()\n",
    "for i,y in enumerate(occs):\n",
    "    occ_encoded[y] = onehot_encoded[i,:]\n",
    "users_df[3] = users_df[3].map(occ_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接列1、列2和列3编码得到最后特征矩阵\n",
    "users_df[5] = users_df.apply(lambda x: np.concatenate([x[1],x[2],x[3]]),axis = 1)\n",
    "users_df = users_df[[0,5]]\n",
    "users_df = users_df.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6036</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6037</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6038</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6039</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6040</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      5\n",
       "0                                                      \n",
       "1     [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "3     [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
       "5     [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "...                                                 ...\n",
       "6036  [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "6037  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
       "6038  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "6039  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
       "6040  [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "\n",
       "[6040 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结合rating\n",
    "### 通过movieId和userId找到对应矩阵, 将rating视为分类标签进行预测\n",
    "### 选择rating最高的top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_table('/Users/yihaoli/Desktop/dataset/movielens-1m-dataset/ratings.dat',header=None,sep='::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df[0] = rating_df[0].map(lambda x:users_df.loc[x,5])\n",
    "rating_df[1] = rating_df[1].map(lambda x:movies_df.loc[x,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = rating_df[[0,1,2]]\n",
    "rating_df[3] = rating_df.apply(lambda x: np.concatenate([x[0],x[1]]),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1          [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2          [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3          [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4          [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                                 ...                        \n",
       "1000204    [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1000205    [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1000206    [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1000207    [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1000208    [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: 3, Length: 1000209, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征组合与分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df[3] = rating_df[3].map(lambda x: np.reshape(x,(1,129)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(list(rating_df[3]),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray(rating_df[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDBT训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-34d589eedbea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 太慢了, 换决策树先跑\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "clf = GradientBoostingClassifier(random_state=0,tol = 1e-3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3447149204368674"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 4, 3, 4, 5, 4, 4, 3, 4, 5, 2, 4, 4, 3, 4, 4, 4, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 4, 5, 1, 5, 3, 4, 5, 2, 4, 5, 1, 4, 3, 5, 3, 3, 3, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#training setting\n",
    "batch_size = 64\n",
    "\n",
    "# grab train and test data\n",
    "train_dataset = Data.TensorDataset(torch.tensor(torch.from_numpy(X_train),dtype=torch.float32), torch.tensor(torch.from_numpy(y_train-1),dtype=torch.long))\n",
    "test_dataset = Data.TensorDataset(torch.tensor(torch.from_numpy(X_test),dtype=torch.float32), torch.tensor(torch.from_numpy(y_test-1),dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.l1 = nn.Linear(129, 256)\n",
    "        self.l2 = nn.Linear(256, 64)\n",
    "        self.l3 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,129) # Flattern the (n,1,28,28) to (n,784)\n",
    "        x = F.relu6(self.l1(x))\n",
    "        x = F.relu6(self.l2(x))\n",
    "        x = F.softmax(self.l3(x))\n",
    "\n",
    "        return x\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr= 0.01 , momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # print(len(train_loader))\n",
    "        data,target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data,volatile=True),Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).data.item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/750156 (0%)]\tLoss: 1.610901\n",
      "Train Epoch: 1 [320000/750156 (43%)]\tLoss: 1.488907\n",
      "Train Epoch: 1 [640000/750156 (85%)]\tLoss: 1.564952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 89226/250053 (36%)\n",
      "\n",
      "Train Epoch: 2 [0/750156 (0%)]\tLoss: 1.524418\n",
      "Train Epoch: 2 [320000/750156 (43%)]\tLoss: 1.512048\n",
      "Train Epoch: 2 [640000/750156 (85%)]\tLoss: 1.501196\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 90620/250053 (36%)\n",
      "\n",
      "Train Epoch: 3 [0/750156 (0%)]\tLoss: 1.500295\n",
      "Train Epoch: 3 [320000/750156 (43%)]\tLoss: 1.511681\n",
      "Train Epoch: 3 [640000/750156 (85%)]\tLoss: 1.450765\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 92395/250053 (37%)\n",
      "\n",
      "Train Epoch: 4 [0/750156 (0%)]\tLoss: 1.575653\n",
      "Train Epoch: 4 [320000/750156 (43%)]\tLoss: 1.493427\n",
      "Train Epoch: 4 [640000/750156 (85%)]\tLoss: 1.536489\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 93715/250053 (37%)\n",
      "\n",
      "Train Epoch: 5 [0/750156 (0%)]\tLoss: 1.515961\n",
      "Train Epoch: 5 [320000/750156 (43%)]\tLoss: 1.515100\n",
      "Train Epoch: 5 [640000/750156 (85%)]\tLoss: 1.478083\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 93963/250053 (38%)\n",
      "\n",
      "Train Epoch: 6 [0/750156 (0%)]\tLoss: 1.459001\n",
      "Train Epoch: 6 [320000/750156 (43%)]\tLoss: 1.499711\n",
      "Train Epoch: 6 [640000/750156 (85%)]\tLoss: 1.493240\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 94898/250053 (38%)\n",
      "\n",
      "Train Epoch: 7 [0/750156 (0%)]\tLoss: 1.454403\n",
      "Train Epoch: 7 [320000/750156 (43%)]\tLoss: 1.488492\n",
      "Train Epoch: 7 [640000/750156 (85%)]\tLoss: 1.480376\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95651/250053 (38%)\n",
      "\n",
      "Train Epoch: 8 [0/750156 (0%)]\tLoss: 1.493075\n",
      "Train Epoch: 8 [320000/750156 (43%)]\tLoss: 1.502777\n",
      "Train Epoch: 8 [640000/750156 (85%)]\tLoss: 1.547016\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95421/250053 (38%)\n",
      "\n",
      "Train Epoch: 9 [0/750156 (0%)]\tLoss: 1.475898\n",
      "Train Epoch: 9 [320000/750156 (43%)]\tLoss: 1.546103\n",
      "Train Epoch: 9 [640000/750156 (85%)]\tLoss: 1.515857\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 94874/250053 (38%)\n",
      "\n",
      "Train Epoch: 10 [0/750156 (0%)]\tLoss: 1.488953\n",
      "Train Epoch: 10 [320000/750156 (43%)]\tLoss: 1.460571\n",
      "Train Epoch: 10 [640000/750156 (85%)]\tLoss: 1.535503\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95465/250053 (38%)\n",
      "\n",
      "Train Epoch: 11 [0/750156 (0%)]\tLoss: 1.417359\n",
      "Train Epoch: 11 [320000/750156 (43%)]\tLoss: 1.539676\n",
      "Train Epoch: 11 [640000/750156 (85%)]\tLoss: 1.511875\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95093/250053 (38%)\n",
      "\n",
      "Train Epoch: 12 [0/750156 (0%)]\tLoss: 1.437863\n",
      "Train Epoch: 12 [320000/750156 (43%)]\tLoss: 1.465732\n",
      "Train Epoch: 12 [640000/750156 (85%)]\tLoss: 1.506526\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96339/250053 (39%)\n",
      "\n",
      "Train Epoch: 13 [0/750156 (0%)]\tLoss: 1.488185\n",
      "Train Epoch: 13 [320000/750156 (43%)]\tLoss: 1.448448\n",
      "Train Epoch: 13 [640000/750156 (85%)]\tLoss: 1.478188\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96194/250053 (38%)\n",
      "\n",
      "Train Epoch: 14 [0/750156 (0%)]\tLoss: 1.551863\n",
      "Train Epoch: 14 [320000/750156 (43%)]\tLoss: 1.523405\n",
      "Train Epoch: 14 [640000/750156 (85%)]\tLoss: 1.514572\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96505/250053 (39%)\n",
      "\n",
      "Train Epoch: 15 [0/750156 (0%)]\tLoss: 1.469564\n",
      "Train Epoch: 15 [320000/750156 (43%)]\tLoss: 1.457580\n",
      "Train Epoch: 15 [640000/750156 (85%)]\tLoss: 1.530786\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96327/250053 (39%)\n",
      "\n",
      "Train Epoch: 16 [0/750156 (0%)]\tLoss: 1.463845\n",
      "Train Epoch: 16 [320000/750156 (43%)]\tLoss: 1.486295\n",
      "Train Epoch: 16 [640000/750156 (85%)]\tLoss: 1.416351\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96177/250053 (38%)\n",
      "\n",
      "Train Epoch: 17 [0/750156 (0%)]\tLoss: 1.474290\n",
      "Train Epoch: 17 [320000/750156 (43%)]\tLoss: 1.496003\n",
      "Train Epoch: 17 [640000/750156 (85%)]\tLoss: 1.482244\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96643/250053 (39%)\n",
      "\n",
      "Train Epoch: 18 [0/750156 (0%)]\tLoss: 1.482451\n",
      "Train Epoch: 18 [320000/750156 (43%)]\tLoss: 1.532331\n",
      "Train Epoch: 18 [640000/750156 (85%)]\tLoss: 1.534154\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96332/250053 (39%)\n",
      "\n",
      "Train Epoch: 19 [0/750156 (0%)]\tLoss: 1.431385\n",
      "Train Epoch: 19 [320000/750156 (43%)]\tLoss: 1.457510\n",
      "Train Epoch: 19 [640000/750156 (85%)]\tLoss: 1.495391\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95965/250053 (38%)\n",
      "\n",
      "Train Epoch: 20 [0/750156 (0%)]\tLoss: 1.557520\n",
      "Train Epoch: 20 [320000/750156 (43%)]\tLoss: 1.542870\n",
      "Train Epoch: 20 [640000/750156 (85%)]\tLoss: 1.409916\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96453/250053 (39%)\n",
      "\n",
      "Train Epoch: 21 [0/750156 (0%)]\tLoss: 1.489326\n",
      "Train Epoch: 21 [320000/750156 (43%)]\tLoss: 1.475626\n",
      "Train Epoch: 21 [640000/750156 (85%)]\tLoss: 1.527871\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96066/250053 (38%)\n",
      "\n",
      "Train Epoch: 22 [0/750156 (0%)]\tLoss: 1.514417\n",
      "Train Epoch: 22 [320000/750156 (43%)]\tLoss: 1.448924\n",
      "Train Epoch: 22 [640000/750156 (85%)]\tLoss: 1.496701\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96631/250053 (39%)\n",
      "\n",
      "Train Epoch: 23 [0/750156 (0%)]\tLoss: 1.504135\n",
      "Train Epoch: 23 [320000/750156 (43%)]\tLoss: 1.436788\n",
      "Train Epoch: 23 [640000/750156 (85%)]\tLoss: 1.477630\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96090/250053 (38%)\n",
      "\n",
      "Train Epoch: 24 [0/750156 (0%)]\tLoss: 1.424883\n",
      "Train Epoch: 24 [320000/750156 (43%)]\tLoss: 1.434417\n",
      "Train Epoch: 24 [640000/750156 (85%)]\tLoss: 1.501304\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95689/250053 (38%)\n",
      "\n",
      "Train Epoch: 25 [0/750156 (0%)]\tLoss: 1.515715\n",
      "Train Epoch: 25 [320000/750156 (43%)]\tLoss: 1.486767\n",
      "Train Epoch: 25 [640000/750156 (85%)]\tLoss: 1.484667\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96290/250053 (39%)\n",
      "\n",
      "Train Epoch: 26 [0/750156 (0%)]\tLoss: 1.546231\n",
      "Train Epoch: 26 [320000/750156 (43%)]\tLoss: 1.467914\n",
      "Train Epoch: 26 [640000/750156 (85%)]\tLoss: 1.534286\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96160/250053 (38%)\n",
      "\n",
      "Train Epoch: 27 [0/750156 (0%)]\tLoss: 1.457815\n",
      "Train Epoch: 27 [320000/750156 (43%)]\tLoss: 1.485572\n",
      "Train Epoch: 27 [640000/750156 (85%)]\tLoss: 1.478018\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96216/250053 (38%)\n",
      "\n",
      "Train Epoch: 28 [0/750156 (0%)]\tLoss: 1.524993\n",
      "Train Epoch: 28 [320000/750156 (43%)]\tLoss: 1.467866\n",
      "Train Epoch: 28 [640000/750156 (85%)]\tLoss: 1.358591\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96542/250053 (39%)\n",
      "\n",
      "Train Epoch: 29 [0/750156 (0%)]\tLoss: 1.556349\n",
      "Train Epoch: 29 [320000/750156 (43%)]\tLoss: 1.472054\n",
      "Train Epoch: 29 [640000/750156 (85%)]\tLoss: 1.505838\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96317/250053 (39%)\n",
      "\n",
      "Train Epoch: 30 [0/750156 (0%)]\tLoss: 1.472191\n",
      "Train Epoch: 30 [320000/750156 (43%)]\tLoss: 1.360259\n",
      "Train Epoch: 30 [640000/750156 (85%)]\tLoss: 1.367789\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96323/250053 (39%)\n",
      "\n",
      "Train Epoch: 31 [0/750156 (0%)]\tLoss: 1.456537\n",
      "Train Epoch: 31 [320000/750156 (43%)]\tLoss: 1.432060\n",
      "Train Epoch: 31 [640000/750156 (85%)]\tLoss: 1.420097\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96300/250053 (39%)\n",
      "\n",
      "Train Epoch: 32 [0/750156 (0%)]\tLoss: 1.432562\n",
      "Train Epoch: 32 [320000/750156 (43%)]\tLoss: 1.453833\n",
      "Train Epoch: 32 [640000/750156 (85%)]\tLoss: 1.505479\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96414/250053 (39%)\n",
      "\n",
      "Train Epoch: 33 [0/750156 (0%)]\tLoss: 1.444084\n",
      "Train Epoch: 33 [320000/750156 (43%)]\tLoss: 1.435434\n",
      "Train Epoch: 33 [640000/750156 (85%)]\tLoss: 1.496223\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96296/250053 (39%)\n",
      "\n",
      "Train Epoch: 34 [0/750156 (0%)]\tLoss: 1.505226\n",
      "Train Epoch: 34 [320000/750156 (43%)]\tLoss: 1.464111\n",
      "Train Epoch: 34 [640000/750156 (85%)]\tLoss: 1.463372\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96391/250053 (39%)\n",
      "\n",
      "Train Epoch: 35 [0/750156 (0%)]\tLoss: 1.549322\n",
      "Train Epoch: 35 [320000/750156 (43%)]\tLoss: 1.444259\n",
      "Train Epoch: 35 [640000/750156 (85%)]\tLoss: 1.456706\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95870/250053 (38%)\n",
      "\n",
      "Train Epoch: 36 [0/750156 (0%)]\tLoss: 1.506121\n",
      "Train Epoch: 36 [320000/750156 (43%)]\tLoss: 1.477556\n",
      "Train Epoch: 36 [640000/750156 (85%)]\tLoss: 1.488114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96401/250053 (39%)\n",
      "\n",
      "Train Epoch: 37 [0/750156 (0%)]\tLoss: 1.513408\n",
      "Train Epoch: 37 [320000/750156 (43%)]\tLoss: 1.485349\n",
      "Train Epoch: 37 [640000/750156 (85%)]\tLoss: 1.486144\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96359/250053 (39%)\n",
      "\n",
      "Train Epoch: 38 [0/750156 (0%)]\tLoss: 1.452360\n",
      "Train Epoch: 38 [320000/750156 (43%)]\tLoss: 1.422938\n",
      "Train Epoch: 38 [640000/750156 (85%)]\tLoss: 1.510979\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96351/250053 (39%)\n",
      "\n",
      "Train Epoch: 39 [0/750156 (0%)]\tLoss: 1.447664\n",
      "Train Epoch: 39 [320000/750156 (43%)]\tLoss: 1.405495\n",
      "Train Epoch: 39 [640000/750156 (85%)]\tLoss: 1.514308\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95724/250053 (38%)\n",
      "\n",
      "Train Epoch: 40 [0/750156 (0%)]\tLoss: 1.451504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [320000/750156 (43%)]\tLoss: 1.526196\n",
      "Train Epoch: 40 [640000/750156 (85%)]\tLoss: 1.549541\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95867/250053 (38%)\n",
      "\n",
      "Train Epoch: 41 [0/750156 (0%)]\tLoss: 1.499639\n",
      "Train Epoch: 41 [320000/750156 (43%)]\tLoss: 1.478392\n",
      "Train Epoch: 41 [640000/750156 (85%)]\tLoss: 1.531389\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96263/250053 (38%)\n",
      "\n",
      "Train Epoch: 42 [0/750156 (0%)]\tLoss: 1.489871\n",
      "Train Epoch: 42 [320000/750156 (43%)]\tLoss: 1.423137\n",
      "Train Epoch: 42 [640000/750156 (85%)]\tLoss: 1.498155\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96196/250053 (38%)\n",
      "\n",
      "Train Epoch: 43 [0/750156 (0%)]\tLoss: 1.489006\n",
      "Train Epoch: 43 [320000/750156 (43%)]\tLoss: 1.529341\n",
      "Train Epoch: 43 [640000/750156 (85%)]\tLoss: 1.543616\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95830/250053 (38%)\n",
      "\n",
      "Train Epoch: 44 [0/750156 (0%)]\tLoss: 1.454494\n",
      "Train Epoch: 44 [320000/750156 (43%)]\tLoss: 1.409032\n",
      "Train Epoch: 44 [640000/750156 (85%)]\tLoss: 1.493120\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95832/250053 (38%)\n",
      "\n",
      "Train Epoch: 45 [0/750156 (0%)]\tLoss: 1.422083\n",
      "Train Epoch: 45 [320000/750156 (43%)]\tLoss: 1.491568\n",
      "Train Epoch: 45 [640000/750156 (85%)]\tLoss: 1.539425\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95865/250053 (38%)\n",
      "\n",
      "Train Epoch: 46 [0/750156 (0%)]\tLoss: 1.481967\n",
      "Train Epoch: 46 [320000/750156 (43%)]\tLoss: 1.536564\n",
      "Train Epoch: 46 [640000/750156 (85%)]\tLoss: 1.543896\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96152/250053 (38%)\n",
      "\n",
      "Train Epoch: 47 [0/750156 (0%)]\tLoss: 1.470377\n",
      "Train Epoch: 47 [320000/750156 (43%)]\tLoss: 1.457326\n",
      "Train Epoch: 47 [640000/750156 (85%)]\tLoss: 1.473744\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95879/250053 (38%)\n",
      "\n",
      "Train Epoch: 48 [0/750156 (0%)]\tLoss: 1.424608\n",
      "Train Epoch: 48 [320000/750156 (43%)]\tLoss: 1.462552\n",
      "Train Epoch: 48 [640000/750156 (85%)]\tLoss: 1.441076\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96036/250053 (38%)\n",
      "\n",
      "Train Epoch: 49 [0/750156 (0%)]\tLoss: 1.505621\n",
      "Train Epoch: 49 [320000/750156 (43%)]\tLoss: 1.440471\n",
      "Train Epoch: 49 [640000/750156 (85%)]\tLoss: 1.367842\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 95830/250053 (38%)\n",
      "\n",
      "Train Epoch: 50 [0/750156 (0%)]\tLoss: 1.498103\n",
      "Train Epoch: 50 [320000/750156 (43%)]\tLoss: 1.479666\n",
      "Train Epoch: 50 [640000/750156 (85%)]\tLoss: 1.482524\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 96043/250053 (38%)\n",
      "\n",
      "Train Epoch: 51 [0/750156 (0%)]\tLoss: 1.505740\n",
      "Train Epoch: 51 [320000/750156 (43%)]\tLoss: 1.549940\n",
      "Train Epoch: 51 [640000/750156 (85%)]\tLoss: 1.547100\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95704/250053 (38%)\n",
      "\n",
      "Train Epoch: 52 [0/750156 (0%)]\tLoss: 1.431043\n",
      "Train Epoch: 52 [320000/750156 (43%)]\tLoss: 1.512493\n",
      "Train Epoch: 52 [640000/750156 (85%)]\tLoss: 1.467393\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95683/250053 (38%)\n",
      "\n",
      "Train Epoch: 53 [0/750156 (0%)]\tLoss: 1.401473\n",
      "Train Epoch: 53 [320000/750156 (43%)]\tLoss: 1.498223\n",
      "Train Epoch: 53 [640000/750156 (85%)]\tLoss: 1.464479\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95574/250053 (38%)\n",
      "\n",
      "Train Epoch: 54 [0/750156 (0%)]\tLoss: 1.414573\n",
      "Train Epoch: 54 [320000/750156 (43%)]\tLoss: 1.439962\n",
      "Train Epoch: 54 [640000/750156 (85%)]\tLoss: 1.506313\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95943/250053 (38%)\n",
      "\n",
      "Train Epoch: 55 [0/750156 (0%)]\tLoss: 1.441159\n",
      "Train Epoch: 55 [320000/750156 (43%)]\tLoss: 1.349814\n",
      "Train Epoch: 55 [640000/750156 (85%)]\tLoss: 1.432081\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95122/250053 (38%)\n",
      "\n",
      "Train Epoch: 56 [0/750156 (0%)]\tLoss: 1.432567\n",
      "Train Epoch: 56 [320000/750156 (43%)]\tLoss: 1.467481\n",
      "Train Epoch: 56 [640000/750156 (85%)]\tLoss: 1.432080\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95467/250053 (38%)\n",
      "\n",
      "Train Epoch: 57 [0/750156 (0%)]\tLoss: 1.460164\n",
      "Train Epoch: 57 [320000/750156 (43%)]\tLoss: 1.448290\n",
      "Train Epoch: 57 [640000/750156 (85%)]\tLoss: 1.483309\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95590/250053 (38%)\n",
      "\n",
      "Train Epoch: 58 [0/750156 (0%)]\tLoss: 1.441540\n",
      "Train Epoch: 58 [320000/750156 (43%)]\tLoss: 1.419746\n",
      "Train Epoch: 58 [640000/750156 (85%)]\tLoss: 1.456938\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95128/250053 (38%)\n",
      "\n",
      "Train Epoch: 59 [0/750156 (0%)]\tLoss: 1.435775\n",
      "Train Epoch: 59 [320000/750156 (43%)]\tLoss: 1.475165\n",
      "Train Epoch: 59 [640000/750156 (85%)]\tLoss: 1.507870\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 96012/250053 (38%)\n",
      "\n",
      "Train Epoch: 60 [0/750156 (0%)]\tLoss: 1.531081\n",
      "Train Epoch: 60 [320000/750156 (43%)]\tLoss: 1.413995\n",
      "Train Epoch: 60 [640000/750156 (85%)]\tLoss: 1.475559\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95752/250053 (38%)\n",
      "\n",
      "Train Epoch: 61 [0/750156 (0%)]\tLoss: 1.488042\n",
      "Train Epoch: 61 [320000/750156 (43%)]\tLoss: 1.538464\n",
      "Train Epoch: 61 [640000/750156 (85%)]\tLoss: 1.500242\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95536/250053 (38%)\n",
      "\n",
      "Train Epoch: 62 [0/750156 (0%)]\tLoss: 1.444605\n",
      "Train Epoch: 62 [320000/750156 (43%)]\tLoss: 1.444212\n",
      "Train Epoch: 62 [640000/750156 (85%)]\tLoss: 1.448695\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95490/250053 (38%)\n",
      "\n",
      "Train Epoch: 63 [0/750156 (0%)]\tLoss: 1.448910\n",
      "Train Epoch: 63 [320000/750156 (43%)]\tLoss: 1.419291\n",
      "Train Epoch: 63 [640000/750156 (85%)]\tLoss: 1.530884\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95638/250053 (38%)\n",
      "\n",
      "Train Epoch: 64 [0/750156 (0%)]\tLoss: 1.395083\n",
      "Train Epoch: 64 [320000/750156 (43%)]\tLoss: 1.401172\n",
      "Train Epoch: 64 [640000/750156 (85%)]\tLoss: 1.507531\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95126/250053 (38%)\n",
      "\n",
      "Train Epoch: 65 [0/750156 (0%)]\tLoss: 1.444729\n",
      "Train Epoch: 65 [320000/750156 (43%)]\tLoss: 1.439549\n",
      "Train Epoch: 65 [640000/750156 (85%)]\tLoss: 1.415448\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95238/250053 (38%)\n",
      "\n",
      "Train Epoch: 66 [0/750156 (0%)]\tLoss: 1.479630\n",
      "Train Epoch: 66 [320000/750156 (43%)]\tLoss: 1.454333\n",
      "Train Epoch: 66 [640000/750156 (85%)]\tLoss: 1.499614\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95240/250053 (38%)\n",
      "\n",
      "Train Epoch: 67 [0/750156 (0%)]\tLoss: 1.457567\n",
      "Train Epoch: 67 [320000/750156 (43%)]\tLoss: 1.528375\n",
      "Train Epoch: 67 [640000/750156 (85%)]\tLoss: 1.429981\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95399/250053 (38%)\n",
      "\n",
      "Train Epoch: 68 [0/750156 (0%)]\tLoss: 1.520476\n",
      "Train Epoch: 68 [320000/750156 (43%)]\tLoss: 1.430852\n",
      "Train Epoch: 68 [640000/750156 (85%)]\tLoss: 1.430616\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95662/250053 (38%)\n",
      "\n",
      "Train Epoch: 69 [0/750156 (0%)]\tLoss: 1.419740\n",
      "Train Epoch: 69 [320000/750156 (43%)]\tLoss: 1.421996\n",
      "Train Epoch: 69 [640000/750156 (85%)]\tLoss: 1.458734\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95637/250053 (38%)\n",
      "\n",
      "Train Epoch: 70 [0/750156 (0%)]\tLoss: 1.408854\n",
      "Train Epoch: 70 [320000/750156 (43%)]\tLoss: 1.497269\n",
      "Train Epoch: 70 [640000/750156 (85%)]\tLoss: 1.401091\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 95683/250053 (38%)\n",
      "\n",
      "Train Epoch: 71 [0/750156 (0%)]\tLoss: 1.484310\n",
      "Train Epoch: 71 [320000/750156 (43%)]\tLoss: 1.474897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-73cf8f3375fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 训练次数不够\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-da4798e25817>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# print(len(train_loader))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练次数不够\n",
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([4, 1, 4, 5, 1, 5, 3, 4, 5, 2, 4, 5, 1, 4, 3, 5, 3, 3, 3, 2, 5, 1, 4, 2,\n",
      "        2, 3, 5, 3, 4, 3, 4, 4, 4, 4, 5, 4, 4, 2, 5, 3, 5, 4, 1, 3, 2, 1, 3, 5,\n",
      "        5, 3, 3, 5, 3, 2, 1, 4, 4, 4, 4, 4, 2, 5, 3, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihaoli/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data, target in test_loader:\n",
    "    i+=1\n",
    "    output = model(data)\n",
    "    # print(output)\n",
    "    print((output+1).data.max(1, keepdim=True)[1])\n",
    "    print(target+1)\n",
    "    if i ==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(output)):\n",
    "    for j in range(len(output[i])):\n",
    "        if output[i][j] == output[i].max():\n",
    "            res.append(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target+1).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.data.max(1, keepdim=True)[1].numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考\n",
    "### 不使用onehot编码改用数值替换类目的效果\n",
    "###  后续考虑结合协同过滤进行推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
